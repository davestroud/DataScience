---
title: "WebScraping"
author: "David Stroud"
date: "3/6/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
 # General-purpose data wrangling
    library(tidyverse)  
    # Parsing of HTML/XML files  
    library(rvest)    
    # String manipulation
    library(stringr)   
    # Verbose regular expressions
    library(rebus)     
    # Eases DateTime manipulation
    library(lubridate)
```

```{r}
# Landing page for Amazon Review
 url <-'http://www.trustpilot.com/review/www.amazon.com'
```

```{r}
 get_last_page <- function(html){

      pages_data <- html %>% 
                      # The '.' indicates the class
                      html_nodes('.pagination-page') %>% 
                      # Extract the raw text as a list
                      html_text()                   

      # The second to last of the buttons is the one
      pages_data[(length(pages_data)-1)] %>%            
        # Take the raw string
        unname() %>%                                     
        # Convert to number
        as.numeric()                                     
    }
```

```{r}
 first_page <- read_html(url)
    (latest_page_number <- get_last_page(first_page))
```

```{r}
# Generate a list of all relevant html's
list_of_pages <- str_c(url, '?page=', 1:latest_page_number)
```

```{r}
get_reviews <- function(html) {
  html %>%
    # The relevant tag
    html_nodes('.review-body') %>%
    html_text() %>%
    # Convert the list into a vector
    unlist()
}

get_reviewers_names <- function(html) {
  html %>%
    html_nodes('.user-review-name-link') %>%
    html_text() %>%
    unlist()
}
```




















